from cProfile import label

import cv2
import os
import numpy as np
import random
from tqdm import tqdm
import time

from scipy.stats import norm
import shutil
from sklearn.model_selection import train_test_split
from skimage.transform import warp


# 전역 변수 설정
rectangles = []  # 사각형 좌표를 저장할 리스트
start_point = None
end_point = None
drawing = False
delete_mode = False  # 삭제 모드 플래그
image = None
img_copy = None
img_with_text = None  # 텍스트가 추가된 이미지

# 배경 추가 ##############################################################################################################
def add_background_noise(img, background_img, label_file):

   
    # 패딩 값 설정 (상단, 하단, 좌측, 우측)
    # top, bottom, left, right = 800, 800, 800, 800  

    rval = random.randint(100,1000)
    
    top = rval
    bottom = rval
    left = rval
    right = rval
    
    
    """
    Add Gaussian noise to the background outside the bounding boxes.
    """
    original_img = img.copy()
    h, w = original_img.shape[:2]  # 실제 이미지 크기
    

    angle = random.randint(-5, 5) 
    center = (w // 2, h // 2)
    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)

    # 이미지 회전
    original_img = cv2.warpAffine(original_img, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR)

        

    # 패딩 추가하기
    extended_img = cv2.copyMakeBorder(
        original_img, top, bottom, left, right, 
        borderType=cv2.BORDER_CONSTANT, 
        value=[0,0,0]  # 패딩 색상: 흰색
    )


    '''라벨파일애 있는 좌푤를 배경이미지 추가된 만큼 위치 변경'''
    
    hh, ww = extended_img.shape[:2]
    
    boxes = []
    if os.path.exists(label_file):
        with open(label_file, "r") as f:
            lines = f.readlines()
            for line in lines:
                data = line.strip().split()
                if len(data) != 5:
                    continue
                class_id = data[0]  # 클래스 ID
                x_center, y_center, box_width, box_height = map(float, data[1:])

                # YOLO 좌표는 정규화된 값이므로 이미지 크기에 맞게 변환
                x1 = int((x_center - box_width / 2) * w)
                y1 = int((y_center - box_height / 2) * h)
                x2 = int((x_center + box_width / 2) * w)
                y2 = int((y_center + box_height / 2) * h)


                x1 += left
                y1 += top
                x2 += left
                y2 += top

                # YOLO 형식 좌표 계산
                x_center = ((x1 + x2) / 2) / ww
                y_center = ((y1 + y2) / 2) / hh
                box_width = (x2 - x1) / ww
                box_height = (y2 - y1 + abs(angle)*((y2 - y1)*0.1)) / hh


                boxes.append([class_id,x_center,y_center,box_width,box_height])
    

   
    background_img = cv2.resize(background_img, (extended_img.shape[1], extended_img.shape[0]))

    x_start = 0  # 좌측 패딩
    x_end = background_img.shape[1]  # 우측 패딩 끝
    y_start = 0  # 상단 패딩
    y_end = background_img.shape[0]  # 하단 패딩 끝

    
    mask = np.all(extended_img == 0, axis=-1)  # 모든 채널이 0인 부분 찾기 (3채널 기준)
    extended_img[mask] = background_img[mask]  # 마스크된 부분을 overlay_img 픽셀로 교체


    

    return extended_img, boxes

# SHADOW ###############################################################################################################
def generate_spot_light_mask(
    mask_size,
    position=None,
    max_brightness=255,
    min_brightness=0,
    mode="gaussian",
    linear_decay_rate=None,
    speedup=False,
):
    """
    Generate decayed light mask generated by spot light given position, direction. Multiple spotlights are accepted.
    Args:
        mask_size: tuple of integers (w, h) defining generated mask size
        position: list of tuple of integers (x, y) defining the center of spotlight light position,
                  which is the reference point during rotating
        max_brightness: integer that max brightness in the mask
        min_brightness: integer that min brightness in the mask
        mode: the way that brightness decay from max to min: linear or gaussian
        linear_decay_rate: only valid in linear_static mode. Suggested value is within [0.2, 2]
        speedup: use `shrinkage then expansion` strategy to speed up vale calculation
    Return:
        light_mask: ndarray in float type consisting value from max_brightness to min_brightness. If in 'linear' mode
                    minimum value could be smaller than given min_brightness.
    """
    if position is None:
        position = [(random.randint(0, mask_size[0]), random.randint(0, mask_size[1]))]
    if linear_decay_rate is None:
        if mode == "linear_static":
            linear_decay_rate = random.uniform(0.25, 1)
    assert mode in [
        "linear",
        "gaussian",
    ], "mode must be linear_dynamic, linear_static or gaussian"
    mask = np.zeros(shape=(mask_size[1], mask_size[0]), dtype=np.float32)
    if mode == "gaussian":
        mu = np.sqrt(mask.shape[0] ** 2 + mask.shape[1] ** 2)
        dev = mu / 3.5
        mask = _decay_value_radically_norm_in_matrix(
            mask_size, position, max_brightness, min_brightness, dev
        )
    mask = np.asarray(mask, dtype=np.uint8)
    # add median blur
    mask = cv2.medianBlur(mask, 5)
    mask = 255 - mask
    # cv2.imshow("mask", mask)
    # cv2.waitKey(0)
    return mask


def _decay_value_radically_norm_in_matrix(
    mask_size, centers, max_value, min_value, dev
):
    """
    _decay_value_radically_norm function in matrix format
    """
    center_prob = norm.pdf(0, 0, dev)
    x_value_rate = np.zeros((mask_size[1], mask_size[0]))
    for center in centers:
        coord_x = np.arange(mask_size[0])
        coord_y = np.arange(mask_size[1])
        xv, yv = np.meshgrid(coord_x, coord_y)
        dist_x = xv - center[0]
        dist_y = yv - center[1]
        dist = np.sqrt(np.power(dist_x, 2) + np.power(dist_y, 2))
        x_value_rate += norm.pdf(dist, 0, dev) / center_prob
    mask = x_value_rate * (max_value - min_value) + min_value
    mask[mask > 255] = 255
    return mask


def _decay_value_radically_norm(x, centers, max_value, min_value, dev):
    """
    Calculate point value decayed from center following Gaussian decay. If multiple centers are given, value
    from each center sums up while limiting the accumulated value into [0, 255]
    NOTE: assuming light at each center is identical: same brightness and same decay rate
    """
    center_prob = norm.pdf(0, 0, dev)
    x_value_rate = 0
    for center in centers:
        distance = np.sqrt((center[0] - x[0]) ** 2 + (center[1] - x[1]) ** 2)
        x_value_rate += norm.pdf(distance, 0, dev) / center_prob
    x_value = x_value_rate * (max_value - min_value) + min_value
    x_value = 255 if x_value > 255 else x_value
    return x_value


def add_spot_light(
    image,
    light_position=None,
    max_brightness=255,
    min_brightness=0,
    mode="gaussian",
    linear_decay_rate=None,
    transparency=None,
):
    """
    Add mask generated from spot light to given image
    """
    if transparency is None:
        transparency = random.uniform(0.5, 0.85)
    frame = np.copy(image)
    height, width, _ = frame.shape
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    mask = generate_spot_light_mask(
        mask_size=(width, height),
        position=light_position,
        max_brightness=max_brightness,
        min_brightness=min_brightness,
        mode=mode,
        linear_decay_rate=linear_decay_rate,
    )
    hsv[:, :, 2] = hsv[:, :, 2] * transparency + mask * (1 - transparency)
    frame = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    frame[frame > 255] = 255
    frame = np.asarray(frame, dtype=np.uint8)
    return frame


def get_shadow(image_list):
    shadowed_list = []
    for image in image_list:
        shadowed_list.append(add_spot_light(image))
    return shadowed_list


# WARP #################################################################################################################

def add_bend_distortion(original):

    height, width = original.shape[:2]
    horizontal_bend = random.choice(
        (
            0,
            0.005,
            -0.005,
            0.006,
            -0.006,
            0.008,
            -0.008,
            0.002,
            -0.002,
            0.001,
            -0.001,
            0.007,
            -0.007,
        )
    )
    vertical_bend = random.choice(
        (
            0,
            0.005,
            -0.005,
            0.006,
            -0.006,
            0.008,
            -0.008,
            0.002,
            -0.002,
            0.001,
            -0.001,
            0.007,
            -0.007,
        )
    )

    def transform_coords(coords):
        x, y = coords[:, 0], coords[:, 1]
        y_new = y + horizontal_bend * width * np.sin(2 * np.pi * x / width)
        x_new = x + vertical_bend * width * np.sin(2 * np.pi * x / width)
        return np.vstack([x_new, y_new]).T

    warped_original = warp(
        original, transform_coords, mode="constant", cval=0, preserve_range=True
    ).astype(original.dtype)

    return warped_original

root = "/media/jwlee/9611c7a0-8b37-472c-8bbb-66cac63bc1c7/"
version = "ECG_yolov7_datasets"
set_list = ["train","test","valid"]
folder_list = ["images","labels"]

bg_path = os.path.expanduser(os.path.join(os.getcwd(), "bg_noises"))

# import pdb; pdb.set_trace()
# input_folder = root

root += version

if __name__ == "__main__":

    for set in set_list:
        print(f"current set : {set}")
        folder = folder_list[0]
        current_path = os.path.join(root,set,folder)
        os.makedirs(current_path, exist_ok=True)
        print(current_path)
        if os.path.exists(current_path):
            image_directory = os.path.join(root+"/"+set+"/"+"images")
            label_directory = os.path.join(root+"/"+set+"/"+"labels")
            print(image_directory)
            output_image_directory = os.path.expanduser(
                root+"_augmented/"+set+"/"+folder_list[0]
            )
            output_label_directory = os.path.expanduser(
                root+"_augmented/"+"/"+set+"/"+folder_list[1]
            )
            print("출력위치 : ",output_image_directory)

            os.makedirs(output_label_directory, exist_ok=True)
            os.makedirs(output_image_directory, exist_ok=True)
            

            image_files = [
               f for f in os.listdir(image_directory) if f.endswith((".jpg", ".png", ".jpeg"))
            ]  # 이미지 파일
            label_files = [
                f for f in os.listdir(label_directory) if f.endswith((".txt"))
            ]  # 라벨 파일
       
            if image_files is None:
                print("error")
                continue    
            # import pdb; pdb.set_trace()
                
            for image_file, label_file in tqdm(
                    zip(image_files, label_files), total=len(image_files), desc="Processing"
            ):
                    
                img = cv2.imread(os.path.join(image_directory, image_file))
                augimg = img.copy()
                mode = random.choice((True,False))
                    
                    
                    
                if mode:
                    bg_files = [
                        f for f in os.listdir(bg_path) if f.endswith((".jpg", ".png", ".jpeg"))
                    ] 
                    bg = cv2.imread(os.path.join(bg_path,bg_files[random.randrange(0,len(bg_files))]))
                    # import pdb; pdb.set_trace()
                    augimg, boxes = add_background_noise(augimg,background_img=bg,label_file=os.path.join(label_directory, image_file[:-4]+".txt"))
                    cv2.imwrite(os.path.join(output_image_directory, f"{image_file[:-4]}-augmented{image_file[-4:]}"), augimg)
                    for box in boxes:
                        
                        with open(os.path.join(output_label_directory, f"{image_file[:-4]}-augmented.txt"), 'a') as f:
                            classes, x_center, y_center, width, height = box
                            f.write(f"{int(classes)} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
                                

                else:
                    cv2.imwrite(os.path.join(output_image_directory, f"{image_file[:-4]}-augmented{image_file[-4:]}"), augimg)
                    shutil.copy(
                    src=os.path.join(label_directory, label_file),
                    dst=os.path.join(output_label_directory, f"{label_file[:-4]}-augmented{label_file[-4:]}"),
                )
            
                  
                    

                    

                    

          













































































































